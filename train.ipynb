{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e020638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderTransformer(nn.Module):\n",
    "    def __init__(self, n_layers, embedding_dim, vocab_size, context_length, head_size, fc_inner_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.position_encoding = PositionEncoding(embedding_dim, context_length)\n",
    "        self.blocks = nn.Sequential(*[Block(embedding_dim, head_size, context_length, fc_inner_size) for i in range(n_layers)])\n",
    "        self.last_fc = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape (Batch size x Context length)\n",
    "        x = self.embedding(x)\n",
    "        x = self.position_encoding(x)\n",
    "        # x is now of shape (Batch size x Context length x Embedding dim)\n",
    "\n",
    "        x = self.blocks(x)\n",
    "        logits = self.last_fc(x) # Generating next token prediction for each token in context length so at the at we get (batch size x context length x vocab size)\n",
    "\n",
    "        return logits\n",
    "\n",
    "class PositionEncoding(nn.Module):\n",
    "    def __init__(self, embedding_dim, context_len):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros((context_len, embedding_dim)) # Tensor that will store position embeddings so that we dont have to compute them each time\n",
    "\n",
    "        positions = torch.arange(0, context_len, step=1).float().unsqueeze(1)\n",
    "\n",
    "        embedding_indices = torch.arange(0, embedding_dim, step=2)\n",
    "        div_term = 1/1000**(embedding_indices/embedding_dim)\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(positions*div_term)\n",
    "        pe[:, 1::2] = torch.cos(positions*div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, word_embeddings):\n",
    "        batch_size, context_length, embedding_dim = word_embeddings.shape\n",
    "        return word_embeddings + self.pe[:context_length, :] \n",
    "    \n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, head_size, context_length):\n",
    "        super().__init__()\n",
    "\n",
    "        self.query = nn.Linear(embedding_dim, head_size)\n",
    "        self.key = nn.Linear(embedding_dim, head_size)\n",
    "        self.value = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape (Batch size x Context length x Embedding dim)\n",
    "        batch_size, context_length, embedding_dim = x.shape\n",
    "\n",
    "        q = self.query(x) # q is of shape (batch size x context_length x head_size)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x) # v is of shape (batch size x context length x embedding dim)\n",
    "\n",
    "        _, _, head_size = q.shape\n",
    "\n",
    "        # Dot product is of shape (Batch size x context length x context length)\n",
    "        dot_product = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(head_size)) \n",
    "\n",
    "        dot_product_masked = dot_product.masked_fill(self.tril == 0, float(\"-inf\"))\n",
    "\n",
    "        weigths = torch.softmax(dot_product_masked, dim=-1)\n",
    "\n",
    "        new_embedding = torch.matmul(weigths, v) # new embedding of shape (batch size x context length x embedding dim)\n",
    "\n",
    "        return new_embedding\n",
    "        \n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, embedding_dim, head_size, context_length, fc_inner_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = SelfAttention(embedding_dim, head_size, context_length)\n",
    "        self.fc = nn.Sequential(nn.Linear(embedding_dim, fc_inner_size), nn.ReLU(), nn.Linear(fc_inner_size, embedding_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Attention and fc with residual connections\n",
    "        x = self.attention(x) + x\n",
    "        x = self.fc(x) + x\n",
    "        return x # Output is of shape (Batch size x context length x embedding dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cf3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33369a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e98a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_id = {ch: i for i, ch in enumerate(chars)}\n",
    "id_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda text: [char_to_id[character] for character in text]\n",
    "decode = lambda ids: ''.join([id_to_char[index] for index in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d079e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encode(\"Hello mama\"))\n",
    "print(decode(encode(\"Hello mama\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8fee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7316d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 8 # Also called block_size\n",
    "embedding_dim = 2048\n",
    "head_size = 128\n",
    "fc_inner_layer = 4096\n",
    "train_data[:context_length+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714aa929",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:context_length]\n",
    "y = data[1:context_length+1]\n",
    "for t in range(context_length):\n",
    "    print(\"Context:\", x[:t+1], \"Target:\", y[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dd577",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - context_length, (batch_size,)) # random offsets\n",
    "    x = torch.stack([data[i:i+context_length] for i in ix]) # inputs \n",
    "    y = torch.stack([data[i+1:i+context_length+1] for i in ix]) # targets\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(context_length): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = get_batch('train')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecoderTransformer(10, embedding_dim, vocab_size, context_length, head_size, fc_inner_layer)\n",
    "model(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99103f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(context_length):\n",
    "    print(\"Model output:\", model(x[:t+1]).shape)\n",
    "    print(\"Context:\", x[:t+1].shape, \"Target:\", y[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 10000\n",
    "\n",
    "\n",
    "for steps in range(n_epochs):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits = model(xb)\n",
    "    \n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.view(B*T, C) # Reshape because cross_entropy expects inputs as (B, C, T)\n",
    "    yb = yb.view(B*T)\n",
    "    loss = criterion(logits, yb)\n",
    "    \n",
    "    # loss = criterion(logits, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
